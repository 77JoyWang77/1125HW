import os
from pathlib import Path
from dotenv import load_dotenv

# ==================== å°å…¥ LangChain æ¨¡çµ„ ====================
from langchain_community.document_loaders import PyPDFLoader  # PDF åŠ è¼‰å™¨
from langchain_text_splitters import RecursiveCharacterTextSplitter  # æ–‡æœ¬åˆ†å‰²
from langchain_chroma import Chroma  # å‘é‡è³‡æ–™åº«
from langchain_huggingface import HuggingFaceEmbeddings  # æœ¬åœ°åµŒå…¥æ¨¡å‹
from langchain_groq import ChatGroq  # Groq LLM
from langchain_core.prompts import ChatPromptTemplate  # Prompt æ¨¡æ¿
from langchain_core.runnables import RunnablePassthrough  # å¯é‹è¡Œç‰©ä»¶
from langchain_core.output_parsers import StrOutputParser  # è¼¸å‡ºè§£æ

load_dotenv()  # åŠ è¼‰ .env æ–‡ä»¶ä¸­çš„ç’°å¢ƒè®Šæ•¸

# ==================== RAG ç³»çµ±ä¸»é¡ ====================
class PDFRAGSystem:
    """
    RAG (Retrieval-Augmented Generation) ç³»çµ±
    æµç¨‹ï¼šPDF â†’ åˆ†å‰² â†’ å‘é‡åŒ– â†’ å­˜å„² â†’ æª¢ç´¢ â†’ LLM å›ç­”
    """
    
    def __init__(self, groq_api_key=None, chroma_path="./chroma_db_groq"):
        """
        åˆå§‹åŒ– RAG ç³»çµ±
        
        Args:
            groq_api_key: Groq API é‡‘é‘°ï¼ˆä¾†è‡ª https://console.groq.comï¼‰
            chroma_path: å‘é‡è³‡æ–™åº«æœ¬åœ°å­˜å„²è·¯å¾‘
                        - é¦–æ¬¡æœƒå»ºç«‹ï¼Œä¹‹å¾Œå¯é‡è¤‡ä½¿ç”¨
                        - é¿å…æ¯æ¬¡éƒ½é‡æ–°å‘é‡åŒ–
        """
        # 1. è¨­å®š Groq API é‡‘é‘°
        self.api_key = groq_api_key or os.getenv("GROQ_API_KEY")
        if not self.api_key:
            raise ValueError("è«‹è¨­å®š GROQ_API_KEY ç’°å¢ƒè®Šæ•¸æˆ–å‚³å…¥åƒæ•¸")
        
        # 2. è¨­å®šå‘é‡è³‡æ–™åº«è·¯å¾‘
        self.chroma_path = chroma_path
        
        # 3. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆç”¨æ–¼æŠŠæ–‡æœ¬è½‰æˆå‘é‡ï¼‰
        print("ğŸš€ åˆå§‹åŒ– HuggingFace Embeddingsï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰...")
        self.embeddings = HuggingFaceEmbeddings(
            model_name="all-MiniLM-L6-v2"  # 22MBï¼Œé€Ÿåº¦å¿«ï¼Œè¶³å¤ å¥½ç”¨
        )
        print("âœ… Embeddings å·²åŠ è¼‰")
        
        # 4. åˆå§‹åŒ–ï¼ˆç¨å¾Œåœ¨åŠ è¼‰ PDF å¾Œæœƒè¨­å®šï¼‰
        self.vectorstore = None  # å‘é‡è³‡æ–™åº«
        self.retriever = None    # æª¢ç´¢å™¨
        self.chain = None        # RAG éˆ
        self._setup_chain()      # å»ºç«‹ç©ºçš„éˆï¼ˆæœƒåœ¨åŠ è¼‰å‘é‡åº«å¾Œæ›´æ–°ï¼‰
    
    def _setup_chain(self):
        """
        å»ºç«‹ RAG éˆè·¯ï¼ˆæ ¸å¿ƒé‚è¼¯ï¼‰
        æµç¨‹ï¼šç”¨æˆ¶å•é¡Œ â†’ æª¢ç´¢ç›¸é—œæ–‡æœ¬ â†’ çµ„åˆ Prompt â†’ LLM å›ç­”
        """
        # 1. åˆå§‹åŒ– LLMï¼ˆèªè¨€æ¨¡å‹ï¼‰
        llm = ChatGroq(
            model="llama-3.1-8b-instant",  # å…è²»å¿«é€Ÿæ¨¡å‹
            api_key=self.api_key,
            temperature=0.7,                # 0-1ï¼Œè¶Šé«˜è¶Šæœ‰å‰µæ„
            max_tokens=1000                 # æœ€å¤šç”Ÿæˆ 1000 å€‹ token
        )
        
        # 2. å®šç¾© Prompt æ¨¡æ¿
        template = """ä½ æ˜¯ä¸€å€‹æœ‰å¹«åŠ©çš„åŠ©æ‰‹ï¼Œæ ¹æ“šæä¾›çš„æ–‡ä»¶å…§å®¹å›ç­”å•é¡Œã€‚

        æ–‡ä»¶å…§å®¹ï¼š
        {context}

        å•é¡Œï¼š{question}

        è«‹åŸºæ–¼ä¸Šè¿°æ–‡ä»¶å…§å®¹å›ç­”å•é¡Œã€‚å¦‚æœæ–‡ä»¶ä¸­æ²’æœ‰ç›¸é—œä¿¡æ¯ï¼Œè«‹èªªæ˜ã€‚"""
        
        prompt = ChatPromptTemplate.from_template(template)
        
        # 3. æ ¼å¼åŒ–æ–‡æª”å‡½æ•¸ï¼ˆæŠŠæª¢ç´¢åˆ°çš„å¤šå€‹æ–‡æª”åˆä½µï¼‰
        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)
        
        # 4. çµ„å»º RAG éˆ
        # ä½¿ç”¨ LCEL (LangChain Expression Language) èªæ³•
        self.chain = (
            {
                # æª¢ç´¢ç›¸é—œæ–‡æª”ï¼ˆå¦‚æœæœ‰æª¢ç´¢å™¨çš„è©±ï¼‰
                "context": self.retriever | format_docs if self.retriever else RunnablePassthrough(),
                # ç›´æ¥å‚³éç”¨æˆ¶å•é¡Œ
                "question": RunnablePassthrough()
            }
            | prompt      # æŠŠ context å’Œ question æ’å…¥ prompt æ¨¡æ¿
            | llm         # ç™¼é€çµ¦ LLM
            | StrOutputParser()  # æŠŠè¼¸å‡ºè½‰æˆå­—ç¬¦ä¸²
        )
    
    # ==================== PDF åŠ è¼‰æ–¹æ³• ====================
    
    def load_pdf(self, pdf_path):
        """
        åŠ è¼‰å–®å€‹ PDF æ–‡ä»¶
        
        Args:
            pdf_path: PDF æ–‡ä»¶è·¯å¾‘
        
        Returns:
            Document ç‰©ä»¶åˆ—è¡¨
        """
        if not Path(pdf_path).exists():
            raise FileNotFoundError(f"PDF æ–‡ä»¶ä¸å­˜åœ¨ï¼š{pdf_path}")
        
        print(f"ğŸ“– æ­£åœ¨åŠ è¼‰ PDFï¼š{pdf_path}")
        loader = PyPDFLoader(pdf_path)
        pages = loader.load()  # æ¯é è¿”å›ä¸€å€‹ Document ç‰©ä»¶
        
        print(f"âœ… å·²åŠ è¼‰ {len(pages)} é å…§å®¹")
        return pages
    
    def load_multiple_pdfs(self, pdf_dir):
        """
        å¾ç›®éŒ„æ‰¹é‡åŠ è¼‰ PDF æ–‡ä»¶
        
        Args:
            pdf_dir: åŒ…å« PDF çš„ç›®éŒ„è·¯å¾‘
        
        Returns:
            æ‰€æœ‰æ–‡æª”çš„åˆ—è¡¨
        """
        pdf_path = Path(pdf_dir)
        if not pdf_path.is_dir():
            raise NotADirectoryError(f"ç›®éŒ„ä¸å­˜åœ¨ï¼š{pdf_dir}")
        
        all_pages = []
        pdf_files = list(pdf_path.glob("*.pdf"))
        
        if not pdf_files:
            print(f"âš ï¸ åœ¨ {pdf_dir} ä¸­æœªæ‰¾åˆ° PDF æ–‡ä»¶")
            return all_pages
        
        for pdf_file in pdf_files:
            print(f"ğŸ“– æ­£åœ¨åŠ è¼‰ï¼š{pdf_file.name}")
            pages = self.load_pdf(str(pdf_file))
            all_pages.extend(pages)
        
        print(f"âœ… å…±åŠ è¼‰äº† {len(all_pages)} é å…§å®¹")
        return all_pages
    
    # ==================== å‘é‡åŒ–å’Œå­˜å„²æ–¹æ³• ====================
    
    def create_vector_store(self, documents):
        """
        æŠŠæ–‡æª”è½‰æˆå‘é‡ä¸¦å­˜å„²
        
        æ­¥é©Ÿï¼š
        1. åˆ†å‰²æ–‡æª”ï¼ˆ1000 å­—ç¬¦ä¸€å¡Šï¼Œ200 å­—ç¬¦é‡ç–Šï¼‰
        2. å‘é‡åŒ–æ¯ä¸€å¡Š
        3. å­˜å„²åˆ° Chroma è³‡æ–™åº«
        4. å»ºç«‹æª¢ç´¢å™¨
        
        Args:
            documents: Document ç‰©ä»¶åˆ—è¡¨
        """
        # ç¬¬ 1 æ­¥ï¼šåˆ†å‰²æ–‡æœ¬
        print("\nğŸ”„ æ­£åœ¨åˆ†å‰²æ–‡æœ¬...")
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,        # æ¯å¡Š 1000 å­—ç¬¦
            chunk_overlap=200,      # ç›¸é„°å¡Šé‡ç–Š 200 å­—ç¬¦ï¼ˆä¿ç•™ä¸Šä¸‹æ–‡ï¼‰
            separators=["\n\n", "\n", " ", ""]  # å„ªå…ˆæŒ‰æ®µè½ã€å¥å­åˆ†å‰²
        )
        
        chunks = text_splitter.split_documents(documents)
        print(f"âœ… å·²åˆ†å‰²æˆ {len(chunks)} å€‹æ–‡æœ¬å¡Š")
        
        # ç¬¬ 2-3 æ­¥ï¼šå‘é‡åŒ–ä¸¦å­˜å„²
        print("\nğŸ”„ æ­£åœ¨å»ºç«‹å‘é‡è³‡æ–™åº«...")
        print("   (é¦–æ¬¡åŠ è¼‰åµŒå…¥æ¨¡å‹å¯èƒ½éœ€è¦æ™‚é–“)")
        
        self.vectorstore = Chroma.from_documents(
            documents=chunks,
            embedding=self.embeddings,
            persist_directory=self.chroma_path  # æŒä¹…åŒ–å­˜å„²
        )
        print(f"âœ… å‘é‡è³‡æ–™åº«å·²å»ºç«‹ï¼Œå­˜å„²åœ¨ {self.chroma_path}")
        
        # ç¬¬ 4 æ­¥ï¼šå»ºç«‹æª¢ç´¢å™¨ï¼ˆç”¨æ–¼æŸ¥æ‰¾ç›¸ä¼¼æ–‡æœ¬ï¼‰
        self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": 3})
        # k=3 è¡¨ç¤ºæ¯æ¬¡æŸ¥è©¢è¿”å›æœ€ç›¸ä¼¼çš„ 3 å€‹æ–‡æœ¬å¡Š
        
        # é‡æ–°å»ºç«‹ RAG éˆï¼ˆç¾åœ¨æœ‰äº†æª¢ç´¢å™¨ï¼‰
        self._setup_chain()
    
    def load_existing_vectorstore(self):
        """
        åŠ è¼‰å·²å­˜åœ¨çš„å‘é‡è³‡æ–™åº«ï¼ˆé¿å…é‡è¤‡å‘é‡åŒ–ï¼‰
        
        Returns:
            æ˜¯å¦åŠ è¼‰æˆåŠŸ
        """
        if not Path(self.chroma_path).exists():
            print(f"âš ï¸ å‘é‡è³‡æ–™åº«ä¸å­˜åœ¨æ–¼ {self.chroma_path}")
            return False
        
        print(f"ğŸ“‚ æ­£åœ¨åŠ è¼‰å‘é‡è³‡æ–™åº«...")
        self.vectorstore = Chroma(
            persist_directory=self.chroma_path,
            embedding_function=self.embeddings
        )
        self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": 3})
        self._setup_chain()
        print("âœ… å‘é‡è³‡æ–™åº«å·²åŠ è¼‰")
        return True
    
    # ==================== æŸ¥è©¢æ–¹æ³• ====================
    
    def query(self, question):
        """
        æå‡ºå•é¡Œä¸¦ç²å–ç­”æ¡ˆ
        
        æµç¨‹ï¼š
        1. å‘é‡åŒ–å•é¡Œ
        2. åœ¨å‘é‡è³‡æ–™åº«ä¸­æœç´¢ç›¸ä¼¼æ–‡æœ¬
        3. æŠŠæ–‡æœ¬å’Œå•é¡Œç™¼çµ¦ LLM
        4. è¿”å› LLM çš„å›ç­”
        
        Args:
            question: ç”¨æˆ¶å•é¡Œ
        
        Returns:
            LLM çš„ç­”æ¡ˆ
        """
        if not self.chain:
            raise ValueError("RAG ç³»çµ±æœªåˆå§‹åŒ–ï¼Œè«‹å…ˆåŠ è¼‰ PDF")
        
        print(f"\nâ“ å•é¡Œï¼š{question}")
        print("ğŸ”„ æ­£åœ¨æ€è€ƒä¸­...")
        answer = self.chain.invoke(question)
        print(f"ğŸ’¬ ç­”æ¡ˆï¼š{answer}")
        return answer
    
    def interactive_chat(self):
        """
        é€²å…¥äº’å‹•å°è©±æ¨¡å¼
        ç”¨æˆ¶å¯ä»¥æŒçºŒæå•ï¼Œè¼¸å…¥ 'exit' é€€å‡º
        """
        print("\nğŸ¤– é€²å…¥äº’å‹•å¼å°è©±æ¨¡å¼ï¼ˆè¼¸å…¥ 'exit' é€€å‡ºï¼‰\n")
        
        while True:
            try:
                question = input("ğŸ‘¤ ä½ çš„å•é¡Œï¼š").strip()
                if question.lower() == 'exit':
                    print("ğŸ‘‹ å†è¦‹ï¼")
                    break
                if not question:
                    continue
                self.query(question)
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è¦‹ï¼")
                break


# ==================== ä¸»ç¨‹å¼å…¥å£ ====================

def main():
    """
    ä¸»ç¨‹å¼æµç¨‹ï¼š
    1. åˆå§‹åŒ– RAG ç³»çµ±
    2. åŠ è¼‰ PDFï¼ˆå„ªå…ˆç´šï¼šsample.pdf > ./pdfs > ç¾æœ‰è³‡æ–™åº«ï¼‰
    3. åŸ·è¡Œæ¸¬è©¦æŸ¥è©¢
    4. é€²å…¥äº’å‹•å°è©±
    """
    
    # ç¬¬ 0 æ­¥ï¼šåˆå§‹åŒ–
    print("=" * 50)
    print("ğŸš€ PDF RAG ç³»çµ±å•Ÿå‹•")
    print("=" * 50)
    
    try:
        rag = PDFRAGSystem()
    except ValueError as e:
        print(f"âŒ éŒ¯èª¤ï¼š{e}")
        return
    
    # ç¬¬ 1 æ­¥ï¼šåŠ è¼‰ PDF
    print("\n" + "=" * 50)
    print("ç¬¬ä¸€æ­¥ï¼šåŠ è¼‰ PDF æ–‡ä»¶")
    print("=" * 50)
    
    # å˜—è©¦æ–¹å¼ Aï¼šåŠ è¼‰ sample.pdf
    pdf_file = "sample.pdf"
    if Path(pdf_file).exists():
        documents = rag.load_pdf(pdf_file)
        rag.create_vector_store(documents)
    else:
        # å˜—è©¦æ–¹å¼ Bï¼šåŠ è¼‰ ./pdfs ç›®éŒ„ä¸­çš„æ‰€æœ‰ PDF
        pdf_dir = "./pdfs"
        if Path(pdf_dir).exists():
            documents = rag.load_multiple_pdfs(pdf_dir)
            if documents:
                rag.create_vector_store(documents)
        else:
            # å˜—è©¦æ–¹å¼ Cï¼šä½¿ç”¨å·²å­˜çš„å‘é‡è³‡æ–™åº«
            if not rag.load_existing_vectorstore():
                print("\nâŒ è«‹æä¾› PDF æ–‡ä»¶")
                print("   æ–¹å¼ 1ï¼šåœ¨ç•¶å‰ç›®éŒ„æ”¾ sample.pdf")
                print("   æ–¹å¼ 2ï¼šåœ¨ ./pdfs ç›®éŒ„æ”¾ PDF æ–‡ä»¶")
                print("   æ–¹å¼ 3ï¼šä½¿ç”¨å·²å»ºç«‹çš„ chroma_db_groq")
                return
    
    # ç¬¬ 2 æ­¥ï¼šåŸ·è¡Œæ¸¬è©¦æŸ¥è©¢
    print("\n" + "=" * 50)
    print("ç¬¬äºŒæ­¥ï¼šé€²è¡Œå•ç­”")
    print("=" * 50)
    
    test_questions = [
        "æ–‡ä»¶çš„ä¸»è¦å…§å®¹æ˜¯ä»€éº¼ï¼Ÿ",
        "è«‹ç¸½çµæ–‡ä»¶ä¸­çš„é—œéµä¿¡æ¯",
    ]
    
    for q in test_questions:
        try:
            rag.query(q)
        except Exception as e:
            print(f"âŒ æŸ¥è©¢æ™‚å‡ºéŒ¯ï¼š{e}")
    
    # ç¬¬ 3 æ­¥ï¼šé€²å…¥äº’å‹•å°è©±
    rag.interactive_chat()


# ==================== ç¨‹å¼å…¥å£ ====================

if __name__ == "__main__":
    main()
